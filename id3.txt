import pandas as pd
df_tennis=pd.read_csv("Prog 3a-data3_test.csv")
print("\n Given play tennis data set :\n\n",df_tennis)      
def entropy(probs):
    import math
    return sum([ -prob*math.log(prob,2) for prob in probs])
def entropy_of_list(a_list):
    from collections import Counter
    cnt=Counter(x for x in a_list)
    num_instances=len(a_list)
    probs=[x/num_instances for x in cnt.values()]
    return entropy(probs)
total_entropy=entropy_of_list(df_tennis['Answer'])
print("\n Total entropy of play tennis dataset:",total_entropy)
def information_gain(df,split_attribute_name,target_attribute_name,trace=0):
    df_split=df.groupby(split_attribute_name)
    for name,group in df_split:
        nobs=len(df.index)
    df_agg_cnt=df_split.agg({target_attribute_name:[entropy_of_list,lambda x:len(x)/nobs]})[target_attribute_name]
    df_agg_cnt.columns=['Entropy','Propobservations']
    if trace:
        print(df_agg_cnt)
    new_entropy=sum(df_agg_cnt['Entropy']*df_agg_cnt['Propobservations'])
    old_entropy=entropy_of_list(df[target_attribute_name])
    return old_entropy-new_entropy
print('info-gain for Outlook is:'+str(information_gain(df_tennis,'Outlook','Answer')),"\n")
print('info-gain for Humidity is:'+str(information_gain(df_tennis,'Humidity','Answer')),"\n")
print('info-gain for Wind is:'+str(information_gain(df_tennis,'Wind','Answer')),"\n")
print('info-gain for Tempature is:'+str(information_gain(df_tennis,'Temperature','Answer')),"\n")
def id3(df,target_attribute_name,attribute_name,default_class=None):
    from collections import Counter
    cnt=Counter(x for x in df[target_attribute_name])
    if len(cnt)==1:
        return next(iter(cnt))
    elif df.empty or (not attribute_name):
        return default_class
    else:
        default_class=max(cnt.keys())
    gainz=[information_gain(df,attr,target_attribute_name)for attr in attribute_name]
    index_of_max=gainz.index(max(gainz))
    best_attr=attribute_name[index_of_max]
    tree={best_attr:{}}
    remaining_attribute_names=[i for i in attribute_names if i!=best_attr]
    for attr_val,data_subset in df.groupby(best_attr):
        subtree=id3(data_subset,target_attribute_name,remaining_attribute_names,default_class)
        tree[best_attr][attr_val]=subtree
    return tree
attribute_names=list(df_tennis.columns)
attribute_names.remove('Answer')
from pprint import pprint
tree=id3(df_tennis,'Answer',attribute_names)
print("\n\nThe resultant decision tree is:\n")
pprint(tree)
def predict(query,tree,default=1):
    for key in list(query.keys()):
        if key in list(tree.keys()):
            try:
                result=tree[key][query[key]]
            except:
                return default 
            result=tree[key][query[key]]
            if isinstance(result,dict):
                return predict(query,result)
            else:
                return result
query={'Outlook':'sunny','Temperature':'hot','Humidity':'high','Wind':'weak'}
answer=predict(query,tree)
print('\nCan tennis be played for the given sample: '+answer)